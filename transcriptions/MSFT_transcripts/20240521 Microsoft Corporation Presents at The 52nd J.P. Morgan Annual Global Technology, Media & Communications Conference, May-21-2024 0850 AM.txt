Microsoft Corporation Presents at The 52nd J.P. Morgan Annual Global Technology, Media & Communications Conference, May-21-2024 08:50 AM
Event Details
May 21, 2024
1:50 PM GMT+1
Corporate Participants
Alysa Taylor Microsoft Corporation · Corporate Vice President of Azure & Industry
Conference Call Participants
Mark Ronald Murphy JPMorgan Chase & Co, Research Division · Managing Director
Event Transcript
Revised May 21, 2024


Prepared Remarks
Mark Ronald MurphyJPMorgan Chase & Co, Research Division · Managing Director
Okay. Welcome, everyone. Good morning. I'm Mark Murphy, software analyst with JPMorgan. And it is a great pleasure to be here this morning with Alysa Taylor, who is CVP of Commercial Cloud and AI with Microsoft. Alysa, I was on stage with you virtually about 4 years ago in the wake of the pandemic and it's so nice to be here with you.
Alysa TaylorMicrosoft Corporation · Corporate Vice President of Azure & Industry
It is nice to be back and in person.
Mark Ronald MurphyJPMorgan Chase & Co, Research Division · Managing Director
Welcome. We really appreciate your time here. Perhaps we can just begin with kind of the brief 1-minute introduction of your background and your current role at Microsoft.
Alysa TaylorMicrosoft Corporation · Corporate Vice President of Azure & Industry
Absolutely. So as you indicated, I'm responsible for our commercial cloud and AI business. My role at Microsoft, I work very closely with our engineering counterparts to determine what services we're going to bring to market. And then my team does all of the pricing, packaging and go-to-market strategy across our Azure business and our industries, global industries.

Question and Answer
Mark Ronald MurphyJPMorgan Chase & Co, Research Division · Managing Director
Thank you. So Alysa, it's very impressive when we think back and we realize that Microsoft made its first investment into OpenAI, way back in 2019, about half decade ago because the topic of generative AI really wasn't something that was mainstream, right? It became mainstream with -- when ChatGPT was released, so it was late 2022. And then, we fast forward to today and that initiative has now blossomed into a 7-point AI tailwind to the Azure business. How do you conceptualize for this audience, the scale of the opportunity here for Microsoft at this point to be in pole position for the era of AI.
Alysa TaylorMicrosoft Corporation · Corporate Vice President of Azure & Industry
Absolutely. Well, the interesting point is we actually brought our first set of Azure AI services to market in 2019. So that was what you think about around cognitive services, traditional machine learning. But what we realized is, the barrier for enterprises to have to take all of their data, do data science work on top of it, it wasn't something that was widely accessible to organizations. And so at that time, working with OpenAI, what we saw was the ability for these large language models to really democratize AI. So to have pretrained models that companies could just, with an API, integrate into those models and not have to do all of the heavy lift with the data science work. And so that was our thesis around the investment into OpenAI and it's paid off as you -- with the introduction of GPT coming to market and these large language models, it's done exactly that. It's allowed organizations to be able to have AI accessible, generative AI in a way that we haven't seen possible.
Mark Ronald MurphyJPMorgan Chase & Co, Research Division · Managing Director
It certainly has. So how do you convey -- in your role, Alysa, how do you convey to customers that Microsoft really should be their primary platform for all their Gen AI activity moving forward? As opposed to the alternative would be doing that work on a competing hyperscaler or maybe one of these GPU as a service providers, what is the marketing message around Microsoft's core differentiators that you're trying to bring to customers?
Alysa TaylorMicrosoft Corporation · Corporate Vice President of Azure & Industry
We start with the Microsoft Cloud. So we have infused AI at every layer of the Microsoft Cloud. So if you think about our first-party assets, the Microsoft 365, Dynamics, GitHub, which is our developer services, our Power platform, our security services. So that's our Copilot layer, our first party Copilot layer. We recently introduced the Copilot Studio, which is the service that allows organizations to customize and extend our first-party copilots and then at Build last year, which is kicking off today, we introduced the Copilot stack. And so that's where organizations that want to build their own unique AI solutions and that's everything from the infrastructure layer, the data layer, what we do around the foundational models, as well as the AI orchestration and tool chain.
And so when you ask about differentiation, it is really the completeness of everything from the first-party copilots, the extensibility of those copilots and then the copilot stack to have organizations build their own unique AI solutions.
Mark Ronald MurphyJPMorgan Chase & Co, Research Division · Managing Director
We're trying to track all those Build announcements in real time, while we're over here at the conference and it's been really impressive what we have been able to catch on that. When you think about, Alysa, what is going to be happening with the foundation models, do you expect that we're going to see some convergence in the capabilities across those -- people probably -- obviously have the GPT models, Anthropic is out there and others. Or do you suspect that we're going to see the release of GPT-5, presumably sometime fairly soon and that this would show some kind of a sustained performance differential. And I'm wondering because I think we're trying to think through all those scenarios.
In the convergence scenario, how would Microsoft perpetuate a structural advantage in AI? In other words, is it going to come down to what you're trying to do with the first-party silicon, would it be having a broader family of -- across all the models, you've got the small language models. Is it going to come down to something you're doing in security and governance?
Alysa TaylorMicrosoft Corporation · Corporate Vice President of Azure & Industry
So there's a lot in there. So I think I'll start with the model part of it. We don't believe there is one model to rule them all. We actually believe in a variety of what we call fit-to-purpose models. So we have in our model catalog today, 1,700 models. And those are, as you indicated, across large language models, proprietary, as well as open source, third-party models and then the introduction of the small language models. So [ 53 ] is our open source that we just announced. And so having this range of models, we think is something that allows organizations to use those models for very specific purposes.
And we also see organizations bringing models together to drive optimal efficiency and performance. In fact, the Microsoft Copilot is a combination of GPT-3, 3.5, 4 and Meta's Llama model. So that's a great example of where even in our first-party copilot, we are using a combination of models for that optimal performance. So that's where we are on the model side of it. To your point around then, how do you bring the governance and the security into those models. I think that is one of the things that I get most often when I'm talking to customers is, how do we govern the data that the models reason over. And so we introduced a product called Microsoft Purview, it is our data governance solution.
It is one of the things that is the most important assets for an organization to be able to use Purview to do all of the governance work. And then we are building security directly into our AI services. So we introduced things like the Azure content safety which is a tool that allows organizations to both detect and mitigate biases in the model. And so I think it is ultimately the range of models, how you bring those models together and then how you govern and secure the models.
Mark Ronald MurphyJPMorgan Chase & Co, Research Division · Managing Director
Okay. That range and breadth is obviously quite impressive already. If we then try to think about, Alysa, the way that's manifesting in customer conversations around AI. Externally, so we can see, again, you've got the 7-point tailwind that has developed from AI services in Azure. We can see -- there have been these huge announcements. We've seen it with Coca-Cola. We've seen it with Cloud Software Group. There have been a bunch of others. We don't always know exactly what it is that they're building. And I thought, given you also run go-to-market for global industry, that maybe you would have a window into this to help us understand. So what is the manufacturer, retailer or an insurance firm building at the moment?
Alysa TaylorMicrosoft Corporation · Corporate Vice President of Azure & Industry
I always start from the horizontal scenario. So I'll do that and then I'll go into industry, which is your specific question. We see probably 3 universal use cases across any industry, how organizations are working with their customers, particularly generative AI has enabled organizations to do like very tailored, personalized at scale, customer experiences in a way that we've never seen before. There's the employee side of it. So how do you make employees more productive, giving them tools, resources, access to information. And then on the operations side, more efficient operations, being able to rethink workflows. So those are the horizontal scenarios across any industry.
But to your very specific question, then how does that translate into opportunity for industry. We see things like in health care. Physician burnout is one of the greatest challenges within health care. And so generative AI, the combination of both ambient AI and generative AI has allowed physicians to use technology to record patient and physician interaction. The technology can then automatically analyze and generate clinical notes. So that takes a lot of the administrative burden off of the physicians, which is a big contributor to physician burnout. So that's a great health care use case scenario.
We see in the customer engagement side, a great example is Real Madrid. So they are a Spanish football league. They have a very small set of their fans that live in Spain. They have over 500 million fans globally that they have been challenged to reach in near real time in a personalized way. They used AI to be able to create their fan engagement platform. And the interesting thing with their fan engagement platform is, they were able to not only put the matches in the hands of their fans in near real time but they could also analyze the sentiment in real time and then do targeted campaigns to their fans.
And the reason I love this story is that actually they've increased their fan profile base by 400% and their top line revenue by 30%. So this is an area where you see both a use case in an industry and then you also see tangible results. And I think that's the combo that we want to see. The last example I'll give you is in the automotive space. So Volvo is a great example. They used a combination of cognitive services, generative AI to digitize all of their invoices. And so if you think about not only being able to invoice their customers but all of the tracking that goes along with auto maintenance, they actually estimated that their new operational platform, took out 850 manual hours per month.
And so these are the industry use cases where we see the technology coming to bear to solve or create an opportunity and then actual -- have real top line or bottom line results as an association with that.
Mark Ronald MurphyJPMorgan Chase & Co, Research Division · Managing Director
Yes. I'm impressed by the range and the number of layers that where that activity is occurring. And obviously, you're laying out something that's pretty tangible across some huge organizations in terms of the ROI. And so that might be helpful as I lead into the next question where we think about the investments that Microsoft is putting into this. And so your CapEx will have risen from, let's say, roughly $25 billion to probably $60 billion to $70 billion, right? That will have happened in the course of a few years. And Amy Hood, the CFO of the company has been very clear that the investments are based upon demand signals. We've heard this. We've been hearing this repeatedly. But we do see, at the same time, there are questions, certainly in the media, there are these questions, is AI demand for real? Or are we going to find out somehow that people are overbuilding?
So -- what other signals could you help us with that you're seeing that may give us comfort that the CapEx surge is well informed, that it's not speculative, right. And that, that this -- that we're going to have this kind of monetization several years into the future.
Alysa TaylorMicrosoft Corporation · Corporate Vice President of Azure & Industry
It's a very important question. We look at demand in 3 different aspects. So the first is customer demand. And do we see the inbound of customers that want to leverage the new AI services that we've put kind of at every layer of the stack, as I talked about? And it's, we look at customer demand, both from those that are coming in, in a pilot phase. And then we also look at it from the dimension of, is that pilot then translating into an at-scale deployment because both of those components are incredibly important. So they're not just experimenting but they're actually taking it from experimentation into full-scale deployment.
The other dimension that we look at is our ecosystem. As you know, Microsoft is a very ecosystem-driven company. And so we look at the number of partners within our ecosystem that are getting AI specializations and where they are bringing in new customers. We have within our Azure AI services, we have 53,000 active customers. 1/3 of those in the last year are new to Azure. So that is a great signal of we are not only bringing in existing customers but new customers as well. And then the last dimension that we look at is customer commitment. Do we have customers making long-term commitments to the Microsoft services, to the Microsoft platform? And our $100 million-plus contracts have increased 80% year-over-year.
So those -- the customer dimension, our ecosystem dimension, our long-term customer commitments are how we triangulate demand. And then we weekly, as a senior leadership team, look at that demand against supply. So it is an ongoing very fluid situation that we manage.
Mark Ronald MurphyJPMorgan Chase & Co, Research Division · Managing Director
So big commitments, long term, the projects are moving from pilots to full deployment and then you're seeing all this partner buy-in. It seems like a pretty good triangulation on it. So let's spend a moment talking about the macro. We haven't heard Microsoft yet call out any kind of a pivot in macro demand. And yet, we think back to this March quarter and we had both commercial bookings in Azure grew 31% year-over-year. These are -- they're healthy results and both of those saw acceleration. There wasn't much acceleration across the software industry but there was there. How would you characterize, Alysa, business willingness to invest at the moment? If I were to say it this way, is there at least an improved sense of stability out there that might be helping on the margin?
Alysa TaylorMicrosoft Corporation · Corporate Vice President of Azure & Industry
Well, if we just look at it from a continuum and I kind of -- I go back to the start of the pandemic, right? As we had organizations move entire group's customer service to a remote capacity, there was an intense capital investment around digitizing foundations, foundational things, customer service environments, supporting employees from a hybrid perspective. And then we came out of the pandemic and we were in a state of cost optimization. So how do organizations take all of that investment that they made in their digitization, in the new kind of digital foundation, their IT investments, how do they then make sure that they rightsize those.
And we worked very closely with our customers to make sure that we were hand-in-hand helping optimize their environment. We are now in a place where they're taking new investment into generative AI, some of the examples that I have given. And there is both the -- how does AI play into their IT investments. But then you also see that translate into what I would call kind of core IT spend, so migrations, continuing to migrate on-prem data app development and the app development building new applications but the change has become a pivot to intelligent app development with the onset of generative AI data, how do you bring together disparate data sets, have an enterprise-wide data architecture and then continuing to invest in developers and making sure that developers are as productive as possible.
And so I think it is both a spike in the -- what we're seeing around generative AI but then also a translation into kind of the core IT functions across migration, app dev, data and developers.
Mark Ronald MurphyJPMorgan Chase & Co, Research Division · Managing Director
That's encouraging.
Alysa TaylorMicrosoft Corporation · Corporate Vice President of Azure & Industry
It is. It is. We are also encouraged.
Mark Ronald MurphyJPMorgan Chase & Co, Research Division · Managing Director
So then let's go a little deeper into that in terms of the workload migrations. When we go back and look at our recent survey, Microsoft partners were calling for an uptick in Azure growth moving forward over the next 12 months. And that is quite rare because it is just such a large-scale business, right? You get some law of large numbers. And we looked at what happened, again subsequently Azure growth, 31%, it accelerated by 3 points. Is there anything else in here that you would call out that is aligning to drive this rebound in Azure growth that we're seeing?
Alysa TaylorMicrosoft Corporation · Corporate Vice President of Azure & Industry
Well, we talked about it from what our customers are doing in that time frame. I would say at that same period of time, we looked internally at where we had placed our investments, particularly in the Azure and the industry side. And the reality is, as Azure had grown as a platform, we were invested in a number of different areas. And we took that moment to say where should we be focused that have the greatest addressable market and where we have the greatest strength. And so we went from what I would say was probably too many areas of disperse focus into a very highly focused GTM. And the core areas that we look at are around migration. We brought new migration tooling to bear. We put new programs in market in the last year.
We've had actually over 10,000 projects come through our migration, what is called Azure migrate and modernize. So we've just become, how do we make sure that we are hand-in-hand working with our customers on migration, data and making sure that we had -- we're bringing new capabilities, both to our analytical databases as well as our operational databases. So we really started to think about data, particularly in the era of AI. Bringing new services into our App Dev portfolio. And so not only on the generative AI stack but then also bringing things like GitHub Copilot for developers to be able to code faster and more efficiently.
And then lastly, on the hybrid space. We introduced at Ignite this past fall, this notion of an adaptive cloud centering on Azure Arc as the central control plane, allowing organizations not only to manage their on-prem but their cloud and multi-cloud environments. So we believe we have one of the strongest hybrid solutions in market. And so that's where we're focused and that's where we spend all of our time, is in those areas. Both from a, where are we innovating at the product level but then also how we are bringing those to market.
Mark Ronald MurphyJPMorgan Chase & Co, Research Division · Managing Director
So -- and I want to come back to that, especially on the data and analytics and the fabric layer just a moment. But to round out the thought on the migrations, you had mentioned, Alysa, an incredible stat a moment ago, the number of $100 million Azure deals being up 80% year-over-year. And our work actually was signaling an improvement in these larger cloud migrations that, that was actually beginning in the back half of the March quarter itself. What is your view on the rate and pace of those types of migrations because it's such a big revenue driver? Do you look at -- do you feel that enterprises are back in an investment mode as it relates to their cloud spend?
Alysa TaylorMicrosoft Corporation · Corporate Vice President of Azure & Industry
Definitely. I think there's 2 vectors we look at or we see customers why they migrate. So the first is, particularly with AI, you are -- we have a saying around, you migrate to innovate because your AI solution is only as good as your underlying data. And that data has to be in a cloud-based environment. And so you see organizations that are migrating their data to be able to apply the new AI services on it. And the more information, the more data you have, the richer your AI solution. And so we have seen the onset of AI help fuel our migration efforts, which is fantastic to see.
The second dimension is cost and how organizations continue to optimize for cost. And migration has been a key component of that. Sapiens is a great example of that. They are an insurance provider. They serve over 600 insurers across 30 countries. They knew that they had on-prem data kind of in different pockets, serving different countries. They migrated over into Azure Arc, as I talked about, keeping some aspects of their platform on-prem, bringing the majority of it into the cloud. They actually have a multi-cloud strategy. They're using Arc as the central control plane to be able to govern their IT and then serve those insurers across their global capacity.
And they were able to take 40% of their operational cost out of the bottom line. And so that is an example of where you're migrating, you're aggregating, you're using a central IT environment to be able to bring down cost.
Mark Ronald MurphyJPMorgan Chase & Co, Research Division · Managing Director
So part of our core thesis, Alysa, has been that Microsoft might, at some point, end up seeing what we were calling an Azure halo effect. And that, that would stem from, again, this early category leadership in generative AI that goes back at least as far as 2019. And we have heard some feedback that there could be some companies out there that had been, let's say, for instance, they were previously sole-sourced on AWS or somewhere else. And they may be thinking of a little different future road map, right? Because of -- there could be a little more consideration of Azure, right, because of these moves you've been making. Is any of that tangible to you, like do you think that you could gain a greater share of cloud workloads because big companies are going to align to your architectural view?
Alysa TaylorMicrosoft Corporation · Corporate Vice President of Azure & Industry
That's one of the very exciting things that we're seeing because you could just use the API into the foundational models and that's it. But we actually are seeing organizations start with the API, bringing in their unstructured data into a blob storage type capacity but then actually moving into more sophisticated analytical data services. Obviously, if you're building an app, you're bringing that into an operational data service. And in fact, of the 53,000 Azure AI customers that I talked about, as I said, 1/3 of those are new to Azure but half of them are actually using our data services as well.
And so it's a good stat that shows the customers are not just using the APIs but also then bringing in their data into the Microsoft platform. And so we're pulling through from the -- just the base sort of integration into the foundational models, actually pulling in our data services as well. And so to your question, the answer is yes. We are seeing customers both come to Azure that were not previously an Azure customer and using services beyond just the core AI services.
Mark Ronald MurphyJPMorgan Chase & Co, Research Division · Managing Director
Okay. So there's adoption of so many services but then we think back to the recent earnings call and Amy had made a comment that near-term AI demand is a bit higher than Microsoft's available capacity, right? So the concept of the capacity constraints came up a bit there. Can you unpack that for us a bit? And one of the questions we get is, should we be somewhat handicapping the forward Azure AI services estimates due to supply constraints? Or do you think that this is something that we can overcome fairly rapidly?
Alysa TaylorMicrosoft Corporation · Corporate Vice President of Azure & Industry
And I think Amy uses that word bit very intentionally because as we talked about, we have the triangulation that we do on the demand side, the customer -- inbound customer the long-term commitments in the ecosystem. And as I indicated, we do that week over week. But I would say we are conservative in our demand. And so we want -- and we do that intentionally because we then take that demand and we marry it against this supply. And so as we make sure that we are conservative in our demand forecasting, we tend to be a bit -- we have a bit more supply constraints but it's nothing material and I would say it has no impact in future forward [indiscernible].
Mark Ronald MurphyJPMorgan Chase & Co, Research Division · Managing Director
Okay. We'll try to be a bit cognizant of that going forward in our model. So then, Amy (sic) [ Alysa ], let's think about Microsoft fabric. We do hear this quite often that what a company is going to need to do is they're going to have to clean. They're going to have to rightsize enterprise data in the age of AI and then clean up that estate to feed it into these large language models. You have Fabric, which is the -- a newer analytics platform and it's definitely been at the forefront of all the discussions lately on the earnings calls. There was a comment about it reaching over 11,000 paid customers in less than 1 year of launch. And can you walk us through what is the customer interest in this Fabric product and are you -- should we think about Microsoft really truly positioning to try to be an end-to-end AI platform when integrated with Azure.
Alysa TaylorMicrosoft Corporation · Corporate Vice President of Azure & Industry
So definitely on the integrated AI platform side and I think you'll see we are building in, across all of our services, the different AI components. Specific to Fabric, we had a thesis about 18 months ago that organizations would want a more unified environment to bring in the different analytic services, be able to aggregate their disparate data into a unified data lake and then be able to bring in AI services directly into that. And so this was a bet that we took over 1.5 years ago.
We introduced Fabric at Build in preview a year ago and it was around the unification of the services into a SaaS environment with a unified business model. Those were all 3 major, major changes for us in how we came to market from an analytics standpoint. So it brought together things like our real-time monitoring, BI, data warehousing, all of that into this notion of Fabric, aggregating into a data lake called OneLake and then we have one meter that goes against it, which before it was all different services that you would then bring together.
And so we introduced Fabric, we actually came to general availability this fall. So we've actually been in market less than 1 year and we have 11,000 paid customers. And a great example of this is General Motor Company. They monitor real-time racing cars. As you can imagine, detecting anomalies in the car is quite important. They adopted Fabric. And prior to bringing together their data into Fabric and being able to do real-time monitoring and the analytics on that real-time monitoring, they had about a 30-minute window before they would know if there was an anomaly with the car and they report today, they're in less than 2 minutes. And so that's the benefit of being able to aggregate into this OneLake environment and then start to bring in the different analytical services across it and then ultimately be able to then do things like vector search and build out those AI solutions. So we are integrating at the Fabric core as well as bringing in our AI services directly into Fabric as well.
Mark Ronald MurphyJPMorgan Chase & Co, Research Division · Managing Director
Okay. So Fabric and OneLake is having that type of an impact. I think we've spent a lot of time, Alysa, so far talking about the software stack and we haven't really gotten into the hardware side, right? As we like -- I think some of us would like to kind of consider the back end that is supporting this whole prior discussion. And going back to late last year, Microsoft announced a couple of very important innovations. Azure Maia and Azure Cobalt, which are chip innovations. Could you walk us through how is it that Microsoft is innovating with first-party silicon now and then what is going to be the benefit of having kind of this tightly integrated hardware and software stack?
Alysa TaylorMicrosoft Corporation · Corporate Vice President of Azure & Industry
So the foundational models, it is important the AI platform that they run on because they are only as efficient and effective as the infrastructure underneath. So I talked about the stack. At the core of that is our AI infrastructure. And as you indicated, we have brought first-party silicon to bear to the market but it is to complement the investments that we have with NVIDIA and AMD. So it is about a portfolio of GPUs and CPUs. And we talk about our AI platform as a systems approach. So bringing together Maia, which is our AI accelerator; Cobalt, which is our CPU; our investments with NVIDIA and AMD but then we wrapper that with networking investments as well as newly talked about liquid cooling to bring together an AI infrastructure that is the most performant for our AI solutions to run on top of.
So it really -- and all of this is opaque to a customer. So when you are a customer and you go in and select whatever Azure service you want to run, we on the back end, are firing across our different silicon investments, again, with that kind of updated networking, storage capacity, so that really the end customer, all they see is the best price to performance and we manage the system on the back end. And it really is an integrated system. And so it isn't about one chip versus the other, NVIDIA versus AMD. It's the portfolio and we do the network load balancing to be able to provide to the end customer the best price and performance.
Mark Ronald MurphyJPMorgan Chase & Co, Research Division · Managing Director
Can you bridge that through to what it's going to mean to developers? We know there's quite a focus on developer tools. You're talking about kind of abstracting all this complexity away from the customer. How do you think about it at a high level, the ability to attract the world's developers and have them build the next generation of all these intelligent apps.
Alysa TaylorMicrosoft Corporation · Corporate Vice President of Azure & Industry
Obviously, developers are at the center and core of all of this. So when we think about our developer ecosystem, we have, over the years, invested in the best tooling and the best tool chain for our developers. So we have GitHub, which has 100 million developers. It is literally the home of open source development. We have Visual Studio, which is the Visual Studio IDE plus VS Code that has 40 million active developers. And then I talked about Copilot Studio, which is our low-code extensible platform for both building new AI copilots as well as extending our first-party copilots. And that actually, in less than 1 year has 30,000 organizations, active organizations.
So we have this full range of the tool chain for developers. And then actually, we are announcing, I think, about 3 minutes ago, new enhancements for GitHub Copilot for Azure, which is allowing developers to use natural language to then be able to code in GitHub Copilot and then use Azure Resource Manager to actually then deploy directly into Azure. So connecting our large 100 million wide ecosystem of developers to build an AI solution and then deploy that directly into Azure. So enhancements we're bringing, also the Visual Studio AI toolkit. So bringing the AI development into our already existing developer base and the tools, DevSecOps tools that they use, the coding tools that they use. So it's a continued investment for us.
Mark Ronald MurphyJPMorgan Chase & Co, Research Division · Managing Director
It's moving rapidly. Alysa, in closing, as you think about the year ahead, what are you most excited about?
Alysa TaylorMicrosoft Corporation · Corporate Vice President of Azure & Industry
I think we've talked a lot about the innovation across the portfolio but ultimately, it comes down to what our industry is doing with it, what are organizations being able to innovate. And I think being in technology right now, we're seeing the adoption of AI services actually happening faster than cloud computing or smartphone adoption. And so it's really an incredible pace. And I think the thing I get most excited about is a lot of this, we talk at the organizational level but there's a human element to it. We look at developers that are more satisfied with their work using GitHub Copilot than they have ever been. And you see individual knowledge workers being more productive, some of the mundane tasks being taken out.
So it's a unique time to see technology innovation at a pace we've never seen and then actually see human satisfaction go up. So it's a really, really unique time in the industry.
Mark Ronald MurphyJPMorgan Chase & Co, Research Division · Managing Director
The pace and the scale and the linkage back to the mission of the company is really incredible to behold at this moment. Alysa, I cannot thank you enough for taking the time to be here with us.
Alysa TaylorMicrosoft Corporation · Corporate Vice President of Azure & Industry
Thank you.